{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c775de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc778ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
      "0             5.1          3.5           1.4          0.2     Setosa\n",
      "1             4.9          3.0           1.4          0.2     Setosa\n",
      "2             4.7          3.2           1.3          0.2     Setosa\n",
      "3             4.6          3.1           1.5          0.2     Setosa\n",
      "4             5.0          3.6           1.4          0.2     Setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  Virginica\n",
      "146           6.3          2.5           5.0          1.9  Virginica\n",
      "147           6.5          3.0           5.2          2.0  Virginica\n",
      "148           6.2          3.4           5.4          2.3  Virginica\n",
      "149           5.9          3.0           5.1          1.8  Virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "iris=pd.read_csv('/Users/glitterlungs/Studia/SEMESTR IV/Systemy sztucznej inteligencji/Zadanie nr 1/iris.csv')\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2792762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingData:\n",
    "    @staticmethod\n",
    "    def shuffleDF(data:pd.DataFrame)->pd.DataFrame:\n",
    "        for i in range(len(data)-1,0,-1):\n",
    "            x=random.randint(0,i)\n",
    "            data.iloc[i], data.iloc[x] = data.iloc[x], data.iloc[i]\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalizeDF(data:pd.DataFrame)->pd.DataFrame:\n",
    "        col=data.columns.tolist()\n",
    "        col=col[:-1]\n",
    "        for j in col:\n",
    "            minn=data[j].min()\n",
    "            maxx=data[j].max()\n",
    "            for i in range(0,len(data),1):\n",
    "                data.at[i,j]=(float(data.at[i,j])- minn)/(maxx - minn)\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def splitDF(data:pd.DataFrame)->pd.DataFrame:\n",
    "        trainDF=pd.DataFrame(columns=data.columns)\n",
    "        testDF=pd.DataFrame(columns=data.columns)\n",
    "        for i in range(len(data)):\n",
    "            if i <= len(data)*0.7:\n",
    "                trainDF=trainDF.append(data.iloc[i])\n",
    "            else:\n",
    "                testDF=testDF.append(data.iloc[i])\n",
    "        return trainDF, testDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07937eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    # srednia arytmetyczna\n",
    "    @staticmethod\n",
    "    def mean(atr: list):\n",
    "        return sum(atr)/len(atr)\n",
    "    \n",
    "    # odchylenie standardowe\n",
    "    @staticmethod\n",
    "    def std(atr: list):\n",
    "        # atr to lista\n",
    "        return np.std(atr)\n",
    "    \n",
    "    # gauss\n",
    "    @staticmethod\n",
    "    def gauss(sampleAtr, mean, std):\n",
    "        exponent = np.exp(-(sampleAtr-mean)**2/(2*std**2))\n",
    "        return 1/(np.sqrt(2*np.pi*std))*exponent\n",
    "    \n",
    "    # klasyfikator Bayesa\n",
    "    @staticmethod\n",
    "    def classify(df: pd.DataFrame, sample: list):\n",
    "        varieties = pd.unique(df[\"variety\"])\n",
    "        attributes = df.columns.tolist()\n",
    "        attributes = attributes[:-1]\n",
    "        \n",
    "        #seperacja df na klasy - dict z variety, w kazdym z variety dict z atributes i w kazdym atributes lista wartosci\n",
    "        variety_atr = {} \n",
    "        mean_std_arr = np.zeros((3,4,2))\n",
    "        for var in varieties:\n",
    "            variety_atr[var] = {}\n",
    "            for atr in attributes:\n",
    "                variety_atr[var][atr] = []\n",
    "                for i in range (len(df)):\n",
    "                    if(df.at[i, \"variety\"] == var):\n",
    "                        variety_atr[var][atr].append(df.at[i,atr])\n",
    "                        # stworzenie tablicy trzywymiarowej [[[m,s]*4]*3], dla kazdego gatunku 4 tablice reprezentujace atrybuty, a w nich dla kazego atrybutu obliczone mean i std\n",
    "                mean_std_arr[np.where(varieties == var)[0][0]][attributes.index(atr)][0] = NaiveBayesClassifier.mean(variety_atr[var][atr])\n",
    "                mean_std_arr[np.where(varieties == var)[0][0]][attributes.index(atr)][1] = NaiveBayesClassifier.std(variety_atr[var][atr])\n",
    "        \n",
    "        # obliczenie składowych prawdopodobieństw (gauss) dla każdego gatunku zapis w dict\n",
    "        result = {}\n",
    "        for var in range(len(varieties)):\n",
    "            result[varieties[var]] = 1/len(varieties)\n",
    "            for atr in range(len(attributes)):\n",
    "                result[varieties[var]] *= NaiveBayesClassifier.gauss(sample[atr], mean_std_arr[var][atr][0],mean_std_arr[var][atr][1])\n",
    "        \n",
    "        return max(result, key=result.get)\n",
    "    \n",
    "    @staticmethod      \n",
    "    def precision(testData: pd.DataFrame, trainData: pd.DataFrame):\n",
    "        good = 0\n",
    "        bad = 0\n",
    "        for sample in testData.values:\n",
    "            if NaiveBayesClassifier.classify(trainData, sample) == sample[-1]:\n",
    "                good += 1\n",
    "            else:\n",
    "                bad += 1\n",
    "                print(\"Sample \" + sample[-1] + \" classifiesd as: \" + NaiveBayesClassifier.classify(trainData, sample))\n",
    "        return good/(bad+good)*100\n",
    "        \n",
    "        \n",
    "        \n",
    "    # w petli dla wszystkich próbek w bazie walidacyjnej\n",
    "    \n",
    "    \n",
    "    # obliczamy dokładność klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe7bc839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal.length  sepal.width  petal.length  petal.width     variety\n",
      "0        0.638889     0.416667      0.576271     0.541667  Versicolor\n",
      "1        0.388889     0.333333      0.525424     0.500000  Versicolor\n",
      "2        0.611111     0.416667      0.813559     0.875000   Virginica\n",
      "3        0.027778     0.375000      0.067797     0.041667      Setosa\n",
      "4        0.194444     0.541667      0.067797     0.041667      Setosa\n",
      "..            ...          ...           ...          ...         ...\n",
      "101      0.111111     0.500000      0.050847     0.041667      Setosa\n",
      "102      0.361111     0.416667      0.525424     0.500000  Versicolor\n",
      "103      0.166667     0.208333      0.593220     0.666667   Virginica\n",
      "104      0.861111     0.333333      0.864407     0.750000   Virginica\n",
      "105      0.722222     0.458333      0.694915     0.916667   Virginica\n",
      "\n",
      "[106 rows x 5 columns]\n",
      "     sepal.length  sepal.width  petal.length  petal.width     variety\n",
      "106      0.583333     0.333333      0.779661     0.875000   Virginica\n",
      "107      0.333333     0.166667      0.474576     0.416667  Versicolor\n",
      "108      0.416667     0.291667      0.694915     0.750000   Virginica\n",
      "109      0.305556     0.791667      0.118644     0.125000      Setosa\n",
      "110      0.416667     0.291667      0.694915     0.750000   Virginica\n",
      "111      0.083333     0.458333      0.084746     0.041667      Setosa\n",
      "112      0.138889     0.583333      0.152542     0.041667      Setosa\n",
      "113      0.388889     0.208333      0.677966     0.791667   Virginica\n",
      "114      0.722222     0.458333      0.661017     0.583333  Versicolor\n",
      "115      0.527778     0.333333      0.644068     0.708333   Virginica\n",
      "116      0.194444     0.583333      0.101695     0.125000      Setosa\n",
      "117      0.305556     0.583333      0.118644     0.041667      Setosa\n",
      "118      0.666667     0.416667      0.677966     0.666667  Versicolor\n",
      "119      0.222222     0.625000      0.067797     0.041667      Setosa\n",
      "120      0.166667     0.458333      0.084746     0.041667      Setosa\n",
      "121      0.555556     0.541667      0.847458     1.000000   Virginica\n",
      "122      0.666667     0.208333      0.813559     0.708333   Virginica\n",
      "123      0.305556     0.583333      0.084746     0.125000      Setosa\n",
      "124      0.416667     0.833333      0.033898     0.041667      Setosa\n",
      "125      0.166667     0.416667      0.067797     0.041667      Setosa\n",
      "126      0.583333     0.500000      0.728814     0.916667   Virginica\n",
      "127      0.388889     0.750000      0.118644     0.083333      Setosa\n",
      "128      0.222222     0.541667      0.118644     0.166667      Setosa\n",
      "129      0.333333     0.916667      0.067797     0.041667      Setosa\n",
      "130      0.083333     0.666667      0.000000     0.041667      Setosa\n",
      "131      0.361111     0.333333      0.661017     0.791667   Virginica\n",
      "132      0.083333     0.500000      0.067797     0.041667      Setosa\n",
      "133      0.500000     0.250000      0.779661     0.541667   Virginica\n",
      "134      0.944444     0.333333      0.966102     0.791667   Virginica\n",
      "135      0.138889     0.416667      0.067797     0.083333      Setosa\n",
      "136      0.944444     0.250000      1.000000     0.916667   Virginica\n",
      "137      0.777778     0.416667      0.830508     0.833333   Virginica\n",
      "138      0.666667     0.541667      0.796610     1.000000   Virginica\n",
      "139      0.222222     0.750000      0.152542     0.125000      Setosa\n",
      "140      0.722222     0.458333      0.745763     0.833333   Virginica\n",
      "141      0.194444     0.500000      0.033898     0.041667      Setosa\n",
      "142      0.444444     0.500000      0.644068     0.708333  Versicolor\n",
      "143      0.694444     0.333333      0.644068     0.541667  Versicolor\n",
      "144      0.305556     0.416667      0.593220     0.583333  Versicolor\n",
      "145      0.666667     0.458333      0.779661     0.958333   Virginica\n",
      "146      0.638889     0.375000      0.610169     0.500000  Versicolor\n",
      "147      0.388889     0.375000      0.542373     0.500000  Versicolor\n",
      "148      0.583333     0.291667      0.728814     0.750000   Virginica\n",
      "149      0.416667     0.333333      0.694915     0.958333   Virginica\n",
      "     sepal.length  sepal.width  petal.length  petal.width     variety\n",
      "0        0.638889     0.416667      0.576271     0.541667  Versicolor\n",
      "1        0.388889     0.333333      0.525424     0.500000  Versicolor\n",
      "2        0.611111     0.416667      0.813559     0.875000   Virginica\n",
      "3        0.027778     0.375000      0.067797     0.041667      Setosa\n",
      "4        0.194444     0.541667      0.067797     0.041667      Setosa\n",
      "..            ...          ...           ...          ...         ...\n",
      "145      0.666667     0.458333      0.779661     0.958333   Virginica\n",
      "146      0.638889     0.375000      0.610169     0.500000  Versicolor\n",
      "147      0.388889     0.375000      0.542373     0.500000  Versicolor\n",
      "148      0.583333     0.291667      0.728814     0.750000   Virginica\n",
      "149      0.416667     0.333333      0.694915     0.958333   Virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "len(train_X):106\n",
      "len(test_X):44\n",
      "--------------\n",
      "Sample Versicolor classifiesd as: Virginica\n",
      "Sample Versicolor classifiesd as: Virginica\n",
      "Sample Versicolor classifiesd as: Virginica\n",
      "93.18181818181817\n"
     ]
    }
   ],
   "source": [
    "iris=ProcessingData.shuffleDF(iris)\n",
    "iris=ProcessingData.normalizeDF(iris)\n",
    "train,test=ProcessingData.splitDF(iris)\n",
    "print(train)\n",
    "print(test)\n",
    "print(iris)\n",
    "\n",
    "print(f\"len(train_X):{len(train)}\")\n",
    "print(f\"len(test_X):{len(test)}\")\n",
    "print(\"--------------\")\n",
    "\n",
    "result = NaiveBayesClassifier()\n",
    "t1 = result.mean([4,5,6])\n",
    "t2 = result.std([4,5,6])\n",
    "t3 = result.gauss(4,t1,t2)\n",
    "t5 = result.precision(test, train)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0fe19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7a8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
